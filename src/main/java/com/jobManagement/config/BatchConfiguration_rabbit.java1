package com.fsit.clarien.recurring.config;

import JobDetailRowMapper;
import CustomJobListener;
import CustomStepListener;
import StepItemProcessListener;
import JobDetail;
import FileUploadJobDetailProcessor;
import JobDetailRepository;
import org.springframework.amqp.core.Binding;
import org.springframework.amqp.core.BindingBuilder;
import org.springframework.amqp.core.Queue;
import org.springframework.amqp.core.TopicExchange;
import org.springframework.amqp.rabbit.connection.ConnectionFactory;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.batch.core.Job;
import org.springframework.batch.core.Step;
import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;
import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;
import org.springframework.batch.core.configuration.annotation.StepScope;
import org.springframework.batch.core.launch.support.RunIdIncrementer;
import org.springframework.batch.core.partition.support.MultiResourcePartitioner;
import org.springframework.batch.core.partition.support.Partitioner;
import org.springframework.batch.item.database.JpaItemWriter;
import org.springframework.batch.item.file.FlatFileItemReader;
import org.springframework.batch.item.file.LineMapper;
import org.springframework.batch.item.file.builder.FlatFileItemReaderBuilder;
import org.springframework.batch.item.file.mapping.BeanWrapperFieldSetMapper;
import org.springframework.batch.item.file.mapping.DefaultLineMapper;
import org.springframework.batch.item.file.transform.DelimitedLineTokenizer;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.core.io.ByteArrayResource;
import org.springframework.core.io.Resource;
import org.springframework.core.io.UrlResource;
import org.springframework.core.io.support.PathMatchingResourcePatternResolver;
import org.springframework.core.io.support.ResourcePatternResolver;
import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;

import javax.persistence.EntityManagerFactory;
import javax.sql.DataSource;
import java.io.IOException;
import java.net.MalformedURLException;

import static Constants.ITEM_READER;
import static Constants.PROCESS_JOB;

//@Configuration
public class BatchConfiguration_rabbit {
    @Autowired
    public JobBuilderFactory jobBuilderFactory;

    @Autowired
    public StepBuilderFactory stepBuilderFactory;
    @Autowired
    EntityManagerFactory emf;
    @Autowired
    private ConnectionFactory rabbitConnectionFactory;

    @Value("${javainuse.rabbitmq.queue}")
    public  String  queueName;

    @Value("${spring.rabbitmq.username}")
    String username;

    @Value("${spring.rabbitmq.password}")
    private String password;
    @Value("${javainuse.rabbitmq.exchange}")
    String exchange;

    @Value("${javainuse.rabbitmq.routingkey}")
    private String routingkey;

    JobDetailRepository jobDetailRepository;

    public static ByteArrayResource byteArrayResource = null;

    private final String JOB_QUERY ="select job.* from Job_Detail job where job.status = 'QUEUED' ORDER BY job.priority ASC";


    @Bean
    Queue queue() {
        return new Queue(queueName, true);
    }
    @Value("${file.upload1.dir}")
    private Resource[] resources;

    @Value("${file.upload1.dir}")
    private String dirName;
    @Bean
    TopicExchange exchange() {
        return new TopicExchange(exchange);
    }
    @Bean
    Binding binding(Queue queue, TopicExchange exchange) {
        return BindingBuilder.bind(queue).to(exchange).with(routingkey);
    }
    @Autowired
    private JpaItemWriter<JobDetail> writer;

    @Autowired
    private FlatFileItemReader<JobDetail> jobDetailItemReader;

    @Bean
    RabbitTemplate rabbitTemplate() {
        RabbitTemplate rabbitTemplate = new RabbitTemplate(rabbitConnectionFactory);
        rabbitTemplate.setExchange(exchange);
        rabbitTemplate.setRoutingKey(routingkey);
        rabbitTemplate.setDefaultReceiveQueue(queueName);
        System.out.println("reached rbtm "+rabbitTemplate);
     //   rabbitTemplate.setTaskExecutor(taskExecutor);
        return rabbitTemplate;
    }

    @Bean
    @StepScope
    //@Qualifier(ITEM_READER)
    public FlatFileItemReader<JobDetail> jobDetailItemReader(@Value("#{jobParameters['fileName']}") String filename) throws MalformedURLException {
        System.out.println("------------ READER "+filename);
        return new FlatFileItemReaderBuilder<JobDetail>()
                .name(ITEM_READER)
                .resource(new UrlResource(filename))
                .delimited()
                .names(new String[]{"name", "type","priority","execution_date","execute_immediate"})
                .lineMapper(lineMapper())
                .fieldSetMapper(new BeanWrapperFieldSetMapper<JobDetail>() {{
                    setTargetType(JobDetail.class);
                }})
                .build();

    }
    @Bean
    public CustomStepListener customStepListener() {
        return new CustomStepListener();
    }

    @Bean
    public Step step1() {
        return stepBuilderFactory.get("step1")
                .<JobDetail, JobDetail>chunk(10)
                .processor(processor())
                .writer(writer)
                .reader(jobDetailItemReader)
                .listener(new StepItemProcessListener())
                .build();
    }
   /* @Bean("partitioner")
    @StepScope*/
    public Partitioner partitioner() {
        System.out.println("In Partitioner");
        MultiResourcePartitioner partitioner = new MultiResourcePartitioner();
        ResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();
        Resource[] resources1 = null;
        try {
            resources1 = resolver.getResources(dirName+"/*.csv");
        } catch (IOException e) {
            e.printStackTrace();
        }
        partitioner.setResources(resources1);
        partitioner.partition(10);
        return partitioner;
    }
  /*  @Bean
    @Qualifier("masterStep")*/
    public Step masterStep() {
        return stepBuilderFactory.get("masterStep")
                .partitioner("step1", partitioner())
                .step(step1())
                .taskExecutor(taskExecutor())
                .build();
    }
    @Bean
    public ThreadPoolTaskExecutor taskExecutor() {
        ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor();
        taskExecutor.setMaxPoolSize(10);
        taskExecutor.setCorePoolSize(10);
        taskExecutor.setQueueCapacity(10);
        taskExecutor.afterPropertiesSet();
        return taskExecutor;
    }
    @Bean
    public LineMapper<JobDetail> lineMapper() {

        final DefaultLineMapper<JobDetail> defaultLineMapper = new DefaultLineMapper<>();
        final DelimitedLineTokenizer lineTokenizer = new DelimitedLineTokenizer();
        lineTokenizer.setDelimiter(",");
        lineTokenizer.setStrict(false);
        lineTokenizer.setNames(new String[] {"name", "type","priority","execution_date","execute_immediate"});
        final JobDetailRowMapper fieldSetMapper = new JobDetailRowMapper();
        defaultLineMapper.setLineTokenizer(lineTokenizer);
        defaultLineMapper.setFieldSetMapper(fieldSetMapper);
        return defaultLineMapper;
    }
    @Bean
    public FileUploadJobDetailProcessor processor() {
        return new FileUploadJobDetailProcessor();
    }
    @Bean
    @StepScope
    public JpaItemWriter<JobDetail> writer(@Value("#{stepExecutionContext['fileName']}") String filename,DataSource dataSource) throws IOException {
        JpaItemWriter<JobDetail> itr = new JpaItemWriter<JobDetail>();
        itr.setEntityManagerFactory(emf);
        return itr;

    }

    /*@Bean
    @Qualifier(ITEM_WRITER)
    public ItemWriter  jobDetailWriter() {
        System.out.println("------------ WRITER");
        *//*return new JdbcBatchItemWriterBuilder<JobDetail>()
                .itemSqlParameterSourceProvider(new BeanPropertyItemSqlParameterSourceProvider<>())
         .sql("INSERT INTO job_detail (name, status,type,priority,execution_Date,execute_Immediate) VALUES (:name, :status,:type,:priority,:executionDate,:executeImmediate)")
                .dataSource(dataSource)
                .build();*//*
        JpaItemWriter writer = new JpaItemWriter();

        writer.setEntityManagerFactory(emf);

        return writer;

    }*/
    @Bean
    public Job job(CustomJobListener listener, Step step1) {
        return jobBuilderFactory.get(PROCESS_JOB)
                .incrementer(new RunIdIncrementer())
                .listener(listener)
                .flow(step1())
  //              .next(step2())
                .end()
                .build();
    }
    public Step step2()  {
        FileDeletingTasklet task = new FileDeletingTasklet();
        return stepBuilderFactory.get("step2")
                .tasklet(task)
                .build();
    }
   /* @Bean
    public Step step(ItemWriter writer,
                                   StepBuilderFactory stepBuilderFactory) throws IOException {
       return  stepBuilderFactory.get(BATCH_STEP)
                .<JobDetail, JobDetail>chunk(4)
               .reader(reader())
                .processor(processor())
                .writer(writer)
                .build();

    }*/
}
